---
kbId: 5135
title: Кластер Comindware Platform. Восстановление после аварий
tags:
    - Ignite
    - Grafana
    - Kafka
    - Loki
    - OpenSearch
    - Prometheus
    - администрирование
    - архитектура
    - балансировка нагрузки
    - восстановление
    - кластер
    - кластеризация
    - мониторинг
    - отказоустойчивость
    - развёртывание
    - резервное копирование
    - управление кластером
hide: tags
---

# Кластер {{ productName }}. Восстановление после аварий {: #cluster_recovery }

{% include-markdown ".snippets/experimental_feature.md" %}

## Введение {: #cluster_recovery_about }

**{{ productName }}** поддерживает кластерные конфигурации, которые обеспечивают высокую доступность, отказоустойчивость и горизонтальное масштабирование.

Здесь представлены рекомендации и процедуры восстановления ПО **{{ productName }}** в кластерных конфигурациях после сбоев.

### Основные принципы восстановления кластера {: #cluster_recovery_philosophy }

Кластерная архитектура **{{ productName }}** позволяет восстанавливать систему благодаря следующим возможностям:

- **Проверка здоровья узлов**: все узлы предоставляют эндпоинт `api/health` для мониторинга состояния.
- **Автоматическое перераспределение трафика**: балансировщик нагрузки должен автоматически исключать неисправные узлы.
- **Резервные узлы**: {{ apacheIgniteVariants }}, {{ openSearchVariants }} и {{ apacheKafkaVariants }} обеспечивают избыточность во время восстановления.
- **Распределённое хранилище**: DFS обеспечивает синхронизацию данных для всех узлов.

При восстановлении кластера **{{ productName }}** соблюдайте рекомендованный порядок:

1. **Диагностика проблемы**: определите причину сбоя и масштаб повреждений.
2. **Выберите стратегию восстановления**: восстановление одного узла или полное восстановление кластера.
3. **Выполните восстановление**: следуйте процедурам для выбранной стратегии.
4. **Проверьте работоспособность**: убедитесь, что все компоненты функционируют корректно.

### Архитектурные основы восстановления {: #cluster_recovery_architecture }

Кластерная архитектура **{{ productName }}** обеспечивает восстановление благодаря следующим компонентам:

**Распределённое хранилище данных {{ apacheIgniteVariants }}** — обеспечивает репликацию данных между узлами, высокую доступность и производительность обработки данных.

**Шина сообщений {{ apacheKafkaVariants }}** — обеспечивает межсервисное взаимодействие и обработку событий.

**Хранилище журналов событий {{ openSearchVariants }}** — обеспечивает сбор, индексирование и обработку журналов распределённых событий.

**Распределённая файловая система (DFS)** — общее хранилище файлов может быть реализовано на NFS или S3. Обеспечивает хранение загружаемых пользовательских файлов и других бинарных данных.

**Управление рабочими процессами** — только один узел выполняет критические фоновые задачи (резервное копирование, обработка процессов).

## Рекомендации по восстановлению кластера {: #cluster_recovery_strategies .pageBreakBefore }

- **Запланируйте восстановление**:
  - Определите причину сбоя и масштаб повреждений.
  - Выберите подходящую стратегию восстановления.
  - Подготовьте план действий и необходимые ресурсы.
- **Заранее протестируйте восстановление в изолированной среде**:
  - Создайте тестовую копию кластера.
  - Протестируйте процедуры восстановления.
  - Проверьте совместимость восстановленного кластера с существующими данными.
- **Контролируйте работоспособность кластера в процессе восстановления**:
  - Отслеживайте состояние всех компонентов и сервисов.
  - Контролируйте состояние топологии кластера {{ apacheIgniteVariants }}.
  - Замеряйте производительность системы.
  - Будьте готовы к немедленному откату при необходимости.

## Ключевые этапы восстановления {: #cluster_recovery_key_principles .pageBreakBefore }

### Подготовка к восстановлению {: #cluster_recovery_preparation }

- Создайте резервную копию данных **{{ productName }}**, чтобы упростить восстановление кластера в случае проблем.
- Проверьте доступность и работоспособность {{ apacheIgniteVariants }}, {{ openSearchVariants }} и {{ apacheKafkaVariants }}, чтобы кластер сохранял работоспособность во время восстановления.
- Проанализируйте журналы на предмет наличия ошибок и предупреждений, которые могут помешать восстановлению.

### Мониторинг во время восстановления {: #cluster_recovery_monitoring }

- Постоянно контролируйте эндпоинт `api/health` на всех узлах, он должен возвращать статус `200`.
- Анализируйте журналы состояния **{{ productName }}** (`heartbeat_*.log`).
- Контролируйте журнал {{ apacheIgniteVariants }} (`igniteClient_*.log`).
- Контролируйте состояние топологии кластера {{ apacheIgniteVariants }} с нескольких узлов во время восстановления.
- Контролируйте синхронизацию данных между узлами.

### Проверка после восстановления {: #cluster_recovery_verification }

- Дождитесь сообщения об окончании ребалансировки кластера.
- Найдите в журналах балансировщика сообщение `INFO Skipping rebalancing (nothing scheduled)`.
- Проверьте результирующую топологию {{ apacheIgniteVariants }} с нескольких узлов.

## Восстановление одного узла {: #cluster_recovery_single_node .pageBreakBefore }

!!! warning "Фактические пути и имена файлов"

    При выполнении инструкций будьте внимательны: указывайте фактические имена файлов и пути, которые используются в вашей системе.

    Такие имена указаны в угловых скобках, например:

    - `<instanceName>` — имя экземпляра ПО, для которого выполняется восстановление;
    - `<osName>` — название операционной системы, для которой предназначен дистрибутив (например, `Astra`);
    - `<versionNumber>` — номер версии ПО.
    - `<path/to>` — путь к директории или файлу в вашей системе; замените на фактический путь согласно своей структуре каталогов.
    - `<serviceName>` — имя службы, которую требуется проверить или остановить (например, `comindware<instanceName>`,`apigateway<instanceName>`, `adapterhost<instanceName>`);
    
    См. _«[Пути и содержимое директорий экземпляра ПО][paths]»_.

### Полное восстановление кластера {: #cluster_recovery_complete_cluster }

### Подготовка к восстановлению

- Убедитесь в наличии актуальной резервной копии данных.
- Проверьте целостность резервных копий.
- Убедитесь в работоспособности {{ apacheIgniteVariants }}, {{ openSearchVariants }} и {{ apacheKafkaVariants }}.
- Проверьте доступность распределённой файловой системы (DFS).

### Восстановление данных

- Остановите все узлы кластера в правильном порядке.
- Восстановите данные из резервной копии на основной узел.
- Восстановите файлы из общего хранилища (NFS).
- Восстановите индексы {{ openSearchVariants }}.
- Восстановите конфигурационные файлы узлов.

### Запуск узлов

- Запустите узлы в порядке приоритета (сначала основной узел, затем дополнительные).
- Запустите службы в правильном порядке: {{ apacheIgniteVariants }} (по необходимости) → {{ productName }} → API Gateway → {{ nginxVariants }}.
- Проверьте подключение каждого узла к кластеру.
- Проверьте подключение каждого узла к сервисам ({{ apacheKafkaVariants }}, {{ opensearchVariants }}).
- Дождитесь сообщения об окончании ребалансировки: `INFO Skipping rebalancing (nothing scheduled)`.

### Проверка восстановления

- Убедитесь, что все узлы возвращают статус `200` на эндпоинте `api/health`.
- Проверьте время отклика всех узлов.
- Протестируйте балансировку нагрузки.

**Протестируйте функциональность:**

- Протестируйте все основные функции **{{ productName }}**.
- Проверьте работу интеграций.
- Проконтролируйте производительность всех компонентов.

**Проверьте синхронизацию данных:**

- Убедитесь в синхронизации данных между узлами.
- Проверьте репликацию в {{ apacheIgniteVariants }}.
- Протестируйте операции чтения/записи.

**Проверьте конфигурацию рабочих процессов:**

- Убедитесь, что только один узел имеет включённые службы `BackupSessionsQueue` и `ProcessEngineQueueProcessing`.
- Проверьте файлы конфигурации на всех узлах:
    - `/usr/share/comindware/configs/instance/<instanceName>.yml`
    - `/var/www/<instanceName>/adapterhost.yml`
    - `/var/www/<instanceName>/apigateway.yml`
<!-- - Проверьте `ConsistentId` на всех узлах в файле `/var/www/<instanceName>/ignite.config`. -->

### Восстановление одного узла {: #cluster_recovery_single_node }

Когда отказывает один узел, остальные узлы кластера продолжают обрабатывать нагрузку. Данные остаются доступными через другие узлы, а конфигурация кластера не теряется.

**Типы узлов:**

- **Узлы сервера приложений** — выполняют функции **{{ productName }}** и участвуют в кластере {{ apacheIgniteVariants }}.
- **Клиентские узлы** — работают в режиме тонкого клиента и подключаются к серверным узлам.
- **Узлы с служебными процессами** — только один узел должен выполнять критические фоновые задачи.

**Стратегии восстановления:**

- **Быстрое восстановление** — перезапуск служб без изменения конфигурации.
- **Восстановление с ребалансировкой** — восстановление данных с других узлов кластера.
- **Полное восстановление узла** — восстановление из резервной копии с последующей ребалансировкой.

### Диагностика отказа узла

- Используйте эндпоинт `api/health` для проверки состояния узла.
- Проверьте журналы состояния экземпляра **{{ productName }}** (`heartbeat_*.log`).
- Проверьте журналы {{ apacheIgniteVariants }} (`igniteClient_*.log`).
- Проверьте состояние файловой системы.
- Проверьте доступность сетевых ресурсов.
- Проверьте текущее состояние топологии кластера {{ apacheIgniteVariants }} со всех узлов.

### Восстановление узла

1. Остановите проблемный узел:

    ``` sh
    systemctl stop comindware<instanceName>
    ```
2. Исправьте выявленные проблемы.
3. При необходимости восстановите из резервной копии.
4. Проверьте конфигурацию узла.
5. Запустите узел:

    ``` sh
    systemctl start comindware<instanceName>
    ```

### Синхронизация с кластером

1. Проверьте подключение к {{ apacheIgniteVariants }}. Для этого выполните на восстановленном и соседнем узлах команду:

    ``` sh
    bash /usr/share/ignite/bin/control.sh --baseline
    ```

2. Удостоверьтесь, что топологии совпадают на всех узлах.
3. Дождитесь сообщения: `INFO Skipping rebalancing (nothing scheduled)` в `igniteClient_*.log`.
4. В случае полного восстановления кластера создайте файл `hold.lock` в директории базы данных. Этот файл служит для блокировки передачи запросов из веб-интерфейса **{{ productName }}** в БД {{ apacheIgniteVariants }} до завершения ребалансировки узла.
5. Удалите файл `hold.lock`, чтобы снова активировать кластер.

### Проверка восстановления

1. Убедитесь, что эндпоинт `api/health` возвращает статус `200`.
2. Проверьте время отклика (не должно превышать 5&nbsp;секунд).
3. Проанализируйте журналы на предмет ошибок.
4. Проверьте синхронизацию данных между узлами.
5. Убедитесь, что критически важные службы активны только на одном узле.

## Мониторинг и диагностика {: #cluster_recovery_monitoring .pageBreakBefore }

### Мониторинг в ходе восстановления {: #cluster_recovery_monitoring_philosophy }

Во время восстановления система находится в переходном состоянии. Мониторинг помогает:

- оценить прогресс восстановления;
- выявить новые проблемы, возникшие в процессе;
- принять решение о готовности системы к полноценной работе

### Ключевые индикаторы состояния {: #cluster_recovery_health_indicators }

**Эндпоинт `api/health`:**

- Статус `200 OK` — узел работает корректно
    - Время отклика не должно превышать 5 секунд
- Проверяйте регулярно, например каждые 30 секунд

**{{ apacheIgniteVariants }}:**

- Контролируйте топологию кластера.
- Отслеживайте состояние репликации данных.
- Контролируйте производительность операций чтения и записи.

**{{ openSearchVariants }}:**

- Используйте эндпоинт `/_cluster/health` для проверки состояния
- Проверяйте состояние индексов и их репликации
- Отслеживайте производительность поисковых запросов

**{{ apacheKafkaVariants }}:**

- Контролируйте состояние топиков и партиций.
- Отслеживайте задержки обработки сообщений.
- Контролируйте размер очередей сообщений.

### Диагностика проблем {: #cluster_recovery_diagnosis }

**Проверьте состояние узлов:**

- Используйте эндпоинт `api/health` для проверки состояния узлов **{{ productName }}**.
- Контролируйте журналы состояния экземпляра **{{ productName }}** (`heartbeat_*.log`).
- Контролируйте журналы {{ apacheIgniteVariants }} (`igniteClient_*.log`).

**Проверьте кластерные компоненты:**

- Проверьте топологию кластера {{ apacheIgniteVariants }} с помощью инструментов управления.
- Используйте эндпоинт `/_cluster/health` для проверки состояния {{ openSearchVariants }}.
- Контролируйте состояние топиков и партиций {{ apacheKafkaVariants }}.

**Анализируйте журналы:**

- Ищите критические ошибки и предупреждения.
- Проверьте сообщения о ребалансировке кластера.
- Отслеживайте производительность операций.

## Устранение неполадок {: #cluster_recovery_troubleshooting .pageBreakBefore }

### Частые проблемы при восстановлении {: #cluster_recovery_common_issues }

- **Узел не подключается к кластеру {{ apacheIgniteVariants }}**: проверьте сетевое подключение между узлами, конфигурацию {{ apacheIgniteVariants }}, файрвол и сетевые настройки.
- **Ошибки синхронизации данных**: проверьте доступность NFS-сервера, права доступа к файлам, состояние дискового пространства, конфигурацию монтирования в `/etc/fstab`.
- **Проблемы с балансировщиком нагрузки**: проверьте конфигурацию балансировщика, доступность эндпоинта `api/health`, настройки проверки состояния узлов.
- **Проблемы с NFS-монтированием**: проверьте доступность NFS-сервера, настройки в `/etc/fstab`, права доступа к общим директориям.

### Журналы для диагностики {: #cluster_recovery_logs }

**Основные журналы {{ productName }}:**

- `heartbeat_*.log` — состояние экземпляра и процесс запуска
- `igniteClient_*.log` — подключение к {{ apacheIgniteVariants }} и ребалансировка кластера

**Журналы инфраструктуры:**

- Журналы {{ apacheIgniteVariants }} — состояние кластера хранилища данных.
- Журналы {{ openSearchVariants }} — состояние кластера журналирования транзакций.
- Журналы {{ apacheKafkaVariants }} — состояние очередей сообщений.

### Инструменты диагностики {: #cluster_recovery_diagnostic_tools }

**Проверка состояния узлов:**

``` sh
curl -X GET "http://<node-ip>/api/health"
```

**Проверка {{ apacheIgniteVariants }}:**

``` sh
bash /usr/share/ignite/bin/control.sh --baseline
```
<-- требуется предварительная настройка -->

**Проверка {{ openSearchVariants }}:**

``` sh
curl -X GET "localhost:9200/_cluster/health?pretty"
```

**Проверка {{ apacheKafkaVariants }}:**

``` sh
kafka-topics.sh --bootstrap-server localhost:9092 --list
```

## Стратегические принципы восстановления {: #cluster_recovery_strategic_principles .pageBreakBefore }

### Подготовка к авариям {: #cluster_recovery_preparation_philosophy }

Чтобы быстрее и надёжнее восстановить систему в случае аварий, рекомендуется регулярно проводить тестирование восстановления:

- команда должна знать процедуры и не должна тратить время на их изучение;
- любые проблемы с восстановлением следует выявлять и устранять в процессе тестирования;
- следует подготовить план действий в нештатных ситуациях.

### Стратегия резервного копирования {: #cluster_recovery_backup_strategy }

**Многоуровневый подход к резервному копированию:**

Современные системы требуют многоуровневого подхода к резервному копированию, где каждый уровень решает свои задачи:

- **Полные резервные копии всей системы** (еженедельно для продуктивных систем, ежемесячно для тестовых) — обеспечивают точку восстановления для критических ситуаций.
- **Инкрементальные копии** (ежедневно для всех систем) — минимизируют потерю данных при ежедневных сбоях.
- **Копии базы данных {{ productName }}** (каждые 4–12 часов в зависимости от критичности) — обеспечивают быстрое восстановление конфигурации и данных экземпляра ПО.
- **Различные периоды хранения** (от 1 дня до 1 месяца) — балансируют между требованиями к хранению и стоимостью.

**Детализированная стратегия резервного копирования по контурам:**

**Продуктивный контур:**
- **Полные копии**: еженедельно (воскресенье), хранение 1 месяц.
- **Инкрементальные копии**: ежедневно (00:00-03:00), хранение 2 недели.
- **Копии базы данных**: не реже 1 раза в 4 часа, хранение не менее одного дня.
- **Автоматизация**: VEEAM для полных и инкрементальных копий, платформа **{{ productName }}** для платформенных копий.

**Предпродуктивный контур:**

- **Полные копии**: ежемесячно, хранение 1 месяц.
- **Инкрементальные копии**: ежедневно (00:00-03:00), хранение 2 недели.
- **Копии базы данных**: каждые 12 часов, хранение 3 дня.

**Тестовый контур:**
- **Полные копии**: ежемесячно, хранение 1 месяц.
- **Инкрементальные копии**: ежедневно (00:00-03:00), хранение 2 недели.
- **Копии базы данных**: каждые 8 часов, хранение 2 дня.

### Тестирование восстановления {: #cluster_recovery_testing }

Регулярное тестирование помогает:
- Выявить проблемы в процедурах восстановления
- Обучить команду работе в нештатных ситуациях
- Проверить актуальность резервных копий
- Оценить время восстановления (RTO) и потери данных (RPO)

**Сценарии тестирования:**

- **Восстановление одного узла** — наиболее частый сценарий, требует регулярного тестирования
- **Полное восстановление кластера** — критический сценарий, тестируется реже, но более тщательно
- **Восстановление по приоритету** — проверяет готовность к частичным сбоям
- **Восстановление в различных условиях** — тестирует устойчивость процедур к различным сценариям

### Мониторинг {: #cluster_recovery_monitoring_culture }

Эффективный мониторинг помогает:
- Предотвратить сбои до их возникновения
- Быстро диагностировать проблемы при их возникновении
- Оценить эффективность восстановительных процедур

**Компоненты мониторинга:**

- **Автоматические уведомления** о критических событиях
- **Регулярные проверки** состояния компонентов
- **Журнал инцидентов**
- **Мониторинг резервных копий**

### Специфика восстановления различных архитектур {: #cluster_recovery_architectures }

**Кластер из толстых узлов:**

- Все узлы имеют полную функциональность
- Восстановление может выполняться в любом порядке
- Убедитесь в правильности конфигурации рабочих процессов

**Кластер с разноролевыми узлами:**

- Восстанавливайте серверные узлы перед клиентскими
- Проверьте конфигурацию тонких клиентов
- Убедитесь в доступности серверных узлов для клиентских

**Кластер с дополнительными узлами {{ apacheIgniteVariants }}:**

- Восстанавливайте узлы {{ apacheIgniteVariants }} перед узлами **{{ productName }}**
- Проверьте топологию кластера {{ apacheIgniteVariants }}
- Убедитесь в правильности конфигурации портов

### Сценарии восстановления по компонентам {: #cluster_recovery_component_scenarios }

**Восстановление основного узла кластера:**

- Требует полной остановки кластера
- Необходима реконфигурация всех дополнительных узлов
- Восстановление данных из последней резервной копии
- Последовательный запуск узлов с реконфигурацией кластера

**Восстановление дополнительного узла кластера:**

- Может выполняться без остановки основного узла
- Восстановление конфигурации и данных узла
- Подключение к существующему кластеру
- Синхронизация данных с основным узлом

**Восстановление инфраструктурных компонентов:**

- **Серверы логирования**: восстановление {{ openSearchVariants }} и {{ apacheKafkaVariants }}
- **Файловые серверы**: восстановление NFS-сервера и общих директорий
- **База данных**: восстановление данных экземпляра **{{ productName }}**

**Восстановление по критичности:**

- **Критичные компоненты**: основные узлы **{{ productName }}**, база данных
- **Важные компоненты**: серверы логирования, файловое хранилище
- **Вспомогательные компоненты**: мониторинг, дополнительные сервисы

### Специфические сценарии восстановления {: #cluster_recovery_specific_scenarios }

**Полное восстановление основного узла кластера:**

При отказе основного узла кластера (например, cmw-node0) требуется полная остановка кластера и последовательное восстановление всех узлов:

- Остановите все службы на остальных узлах кластера в следующем порядке: {{ nginxVariants }} → API Gateway → {{ productName }} → {{ apacheIgniteVariants }}.
- Восстановите основной узел из резервной копию.
- Восстановите данные и конфигурацию **{{ productName }}**.
- Запустите основной узел и проверьте его работоспособность.
- Последовательно восстановите остальные узлы с реконфигурацией кластера.
- Выполните проверку целостности данных и работоспособности системы.

**Полное восстановление дополнительного узла кластера:**

При отказе дополнительного узла (например, cmw-node1 или cmw-node2) восстановление может выполняться без остановки основного узла:

- Восстановите узел из резервной копии
- Очистите локальную базу данных узла
- Настройте ссылки на общие файлы (Scripts)
- Запустите службы в правильном порядке
- Выполните реконфигурацию кластера для подключения узла
- Проверьте синхронизацию данных с основным узлом

**Частичное восстановление сервера {{ productName }}:**

При незначительных сбоях, не требующих полного восстановления:

- Проверьте настройки и доступы согласно документации
- Перезапустите службы в правильном порядке при необходимости
- Проверьте подключение к кластерным компонентам
- Убедитесь в работоспособности **{{ productName }}**

**Восстановление сервера логирования:**

- **Полное восстановление**: восстановите сервер из резервной копии, службы {{ openSearchVariants }} запустятся автоматически
- **Частичное восстановление**: проверьте настройки и перезапустите службу {{ openSearchVariants }} при необходимости

**Восстановление файлового хранилища:**

- Восстановите файловый сервер из резервной копии
- Перезапустите службы на всех узлах **{{ productName }}** поочерёдно
- Проверьте доступность файлов через веб-интерфейс
- Убедитесь в работоспособности управления файлами

**Восстановление базы данных экземпляра {{ productName }}:**

- Остановите все узлы кластера
- Восстановите данные из резервной копии платформы (формат .cdbbz)
- Восстановите файлы скриптов и потоков в общее хранилище
- Настройте ссылки на общие файлы
- Запустите узлы в правильном порядке с реконфигурацией кластера
- Проверьте целостность данных и функциональность

### Восстановление по типам контуров {: #cluster_recovery_environment_scenarios }

**Продуктивный контур:**

- Требует наиболее тщательного планирования и тестирования
- Использует полные резервные копии еженедельно
- Инкрементальные копии ежедневно
- Платформенные копии каждые 4 часа
- Максимальный период хранения резервных копий

**Предпродуктивный контур:**

- Менее критичен, но требует регулярного тестирования
- Полные копии ежемесячно
- Инкрементальные копии ежедневно
- Платформенные копии каждые 12 часов
- Средний период хранения резервных копий

**Тестовый контур:**

- Наименее критичен, но важен для разработки
- Полные копии ежемесячно
- Инкрементальные копии ежедневно
- Платформенные копии каждые 8 часов
- Минимальный период хранения резервных копий

### Практики, которых следует избегать {: #cluster_recovery_anti_patterns }

- **Не игнорируйте резервное копирование**: нерегулярное или неправильное резервное копирование данных может осложнить восстановление системы после сбоя.
- **Не пропускайте тестирование восстановления**: невыполнение регулярного тестирования процедур восстановления может привести к неготовности к авариям.
- **Не восстанавливайте несколько узлов одновременно**: одновременное восстановление нескольких узлов может привести к конфликтам данных.
- **Не игнорируйте проверки целостности**: всегда проверяйте целостность данных после восстановления.
- **Не нарушайте конфигурацию рабочих процессов**: только один узел должен выполнять критические фоновые задачи.

- **Не нарушайте порядок остановки и запуска служб**: неправильный порядок может привести к повреждению данных или неработоспособности кластера.
- **Не игнорируйте реконфигурацию кластера**: после восстановления основного узла необходимо реконфигурировать все дополнительные узлы.
- **Не восстанавливайте компоненты в произвольном порядке**: соблюдайте приоритеты восстановления (критичные → важные → вспомогательные).

<div class="relatedTopics" markdown="block">

--8<-- "related_topics_heading.md"

- [Установка, запуск, инициализация и остановка ПО][deploy_guide_linux]
- [Обновление кластера {{ productName }}][cluster_upgrade]
- [Системные требования {{ productName }}][system_requirements]
- [Резервное копирование. Настройка и запуск, просмотр журнала сеансов][backup_configure]

</div>

{% include-markdown ".snippets/hyperlinks_mkdocs_to_kb_map.md" %}

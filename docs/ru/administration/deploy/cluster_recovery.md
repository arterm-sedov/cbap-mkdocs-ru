---
kbId: 5135
title: Кластер Comindware Platform. Восстановление после аварий
tags:
    - Ignite
    - Grafana
    - Kafka
    - Loki
    - OpenSearch
    - Prometheus
    - администрирование
    - архитектура
    - балансировка нагрузки
    - восстановление
    - кластер
    - кластеризация
    - мониторинг
    - отказоустойчивость
    - развёртывание
    - резервное копирование
    - управление кластером
hide: tags
---

# Кластер Comindware Platform. Восстановление после аварий {: #cluster_recovery }

{% include-markdown ".snippets/experimental_feature.md" %}

## Введение {: #cluster_recovery_about }

**{{ productName }}** поддерживает кластерные конфигурации, которые обеспечивают высокую доступность, отказоустойчивость и горизонтальное масштабирование.

Здесь представлены рекомендации и процедуры восстановления ПО **{{ productName }}** в кластерных конфигурациях после сбоев.

## Средства для обеспечения надежности кластеров {{ productName }} {: #cluster_benefits }

Кластерная архитектура **{{ productName }}** позволяет восстанавливать систему благодаря следующим возможностям:

- **Проверка здоровья узлов**: все узлы предоставляют эндпоинт `api/health` для мониторинга состояния.
- **Автоматическое перераспределение трафика**: балансировщик нагрузки должен автоматически исключать неисправные узлы.
- **Резервные узлы**: {{ apacheIgniteVariants }}, {{ openSearchVariants }} и {{ apacheKafkaVariants }} обеспечивают избыточность во время восстановления.
- **Распределённое хранилище**: DFS обеспечивает сохранность резервных копий и файлов для всех узлов.

## Стратегические принципы обеспечения надёжности системы {: #cluster_recovery_strategic_principles .pageBreakBefore }

### Подготовка к авариям {: #cluster_recovery_preparation_philosophy }

Чтобы быстрее и надёжнее восстановить систему в случае аварий, рекомендуется регулярно проводить тестирование восстановления:

- обеспечить надёжное резервное копирование;
- команда должна знать процедуры и не должна тратить время на их изучение;
- любые проблемы с восстановлением следует выявлять и устранять в процессе тестирования;
- следует подготовить план действий в нештатных ситуациях.

### Стратегия резервного копирования {: #cluster_recovery_backup_strategy }

**Многоуровневый подход к резервному копированию:**

Современные системы требуют многоуровневого подхода к резервному копированию, где каждый уровень решает свои задачи:

- **Полные резервные копии всей системы** (еженедельно для продуктивных систем, ежемесячно для тестовых) — обеспечивают точку восстановления для критических ситуаций.
- **Инкрементальные копии** (ежедневно для всех систем) — минимизируют потерю данных при ежедневных сбоях.
- **Копии базы данных {{ productName }}** (каждые 4–12 часов в зависимости от критичности) — обеспечивают быстрое восстановление конфигурации и данных экземпляра ПО.
- **Различные периоды хранения** (от 1 дня до 1 месяца) — балансируют между требованиями к хранению и стоимостью.

**Детализированная стратегия резервного копирования по контурам:**

**Продуктивный контур:**

- **Полные копии**: еженедельно (воскресенье), хранение 1 месяц.
- **Инкрементальные копии**: ежедневно (00:00—03:00), последние 15 копий.
- **Копии базы данных**: не реже 1 раза в 4 часа, хранение не менее одного дня.
- **Автоматизация**: VEEAM для полных и инкрементальных копий, платформа **{{ productName }}** для платформенных копий.

**Предпродуктивный контур:**

- **Полные копии**: ежемесячно, хранение 1 месяц.
- **Инкрементальные копии**: ежедневно (00:00-03:00), хранение - последние 15 копий.
- **Копии базы данных**: каждые 12 часов, хранение — последние 6 копий.

**Тестовый контур:**

- **Полные копии**: ежемесячно, хранение 1 месяц.
- **Инкрементальные копии**: ежедневно (00:00-03:00), хранение - последние 15 копий.
- **Копии базы данных**: каждые 8 часов, хранение - последние 4 копии.

### Тестирование процедур восстановления {: #cluster_recovery_testing }

**Регулярное тестирование помогает:**

- Выявить проблемы в процедурах восстановления
- Обучить команду работе в нештатных ситуациях
- Проверить актуальность резервных копий
- Оценить время восстановления (RTO) и потери данных (RPO)

**Сценарии тестирования:**

- **Восстановление одного узла** — наиболее частый сценарий, требует регулярного тестирования
- **Полное восстановление кластера** — критический сценарий, тестируется реже, но более тщательно
- **Восстановление в различных условиях** — тестирует устойчивость процедур к различным сценариям

### Мониторинг состояния системы {: #cluster_recovery_monitoring_culture }

**Эффективный мониторинг помогает:**

- Предотвратить сбои до их возникновения
- Быстро диагностировать проблемы при их возникновении
- Оценить эффективность восстановительных процедур

**Компоненты мониторинга:**

- **Автоматические уведомления** о критических событиях
- **Регулярные проверки** состояния компонентов
- **Журнал инцидентов**
- **Мониторинг резервных копий**

## Рекомендации по восстановлению кластера {: #cluster_recovery_strategies .pageBreakBefore }

### Общий порядок восстановления {: #cluster_recovery_sequence }

При восстановлении кластера **{{ productName }}** соблюдайте рекомендованный порядок:

1. **Диагностика проблемы**: определите причину сбоя и масштаб повреждений:

    - Используйте эндпоинт `api/health` для проверки состояния узла.
    - Проверьте журналы состояния экземпляра **{{ productName }}** (`heartbeat_*.log`).
    - Проверьте журналы {{ apacheIgniteVariants }} (`igniteClient_*.log`).
    - Проверьте состояние файловой системы.
    - Проверьте доступность сетевых ресурсов.
    - Проверьте текущее состояние топологии кластера {{ apacheIgniteVariants }} со всех узлов.

2. **Запланируйте восстановление**:
    - Выберите подходящую стратегию восстановления: восстановление одного узла или полное восстановление кластера.
    - Подготовьте план действий и необходимые ресурсы.
3. **Выполните восстановление**: следуйте процедурам для выбранной стратегии.
4. **Контролируйте работоспособность кластера в процессе и после восстановления**:
    - Отслеживайте состояние всех компонентов и сервисов.
    - Контролируйте состояние топологии кластера {{ apacheIgniteVariants }}.
    - Анализируйте файловые журналы на предмет наличия ошибок и предупреждений, которые могут помешать восстановлению.
    - Замеряйте производительность системы.
    - Будьте готовы к немедленному откату при необходимости.

### Мониторинг во время восстановления {: #cluster_recovery_monitoring }

- Постоянно контролируйте эндпоинт `api/health`, на работающих узлах он должен возвращать статус `200`.
- Анализируйте журналы состояния **{{ productName }}** (`heartbeat_*.log`).
- Контролируйте журнал {{ apacheIgniteVariants }} (`igniteClient_*.log`).
- Контролируйте состояние топологии кластера {{ apacheIgniteVariants }} со всех узлов во время восстановления.
- Контролируйте синхронизацию данных между узлами.

!!! warning "Фактические пути и имена файлов"

    При выполнении инструкций будьте внимательны: указывайте фактические имена файлов и пути, которые используются в вашей системе.

    Такие имена указаны в угловых скобках, например:

    - `<instanceName>` — имя экземпляра ПО, для которого выполняется восстановление;
    - `<osName>` — название операционной системы, для которой предназначен дистрибутив (например, `Astra`);
    - `<versionNumber>` — номер версии ПО.
    - `<path/to>` — путь к директории или файлу в вашей системе; замените на фактический путь согласно своей структуре каталогов.
    - `<serviceName>` — имя службы, которую требуется проверить или остановить (например, `comindware<instanceName>`,`apigateway<instanceName>`, `adapterhost<instanceName>`);
    
    См. _«[Пути и содержимое директорий экземпляра ПО][paths]»_.

### Проверка после восстановления {: #cluster_recovery_verification }

- Дождитесь сообщения об окончании ребалансировки кластера - сообщения в журнале  {{ apacheIgniteVariants }} (`igniteClient_*.log`) `INFO Skipping rebalancing (nothing scheduled)`.
- Проверьте результирующую топологию {{ apacheIgniteVariants }} с нескольких узлов.

## Критичность компонентов {: #cluster_recovery_component_criticality }

- **Критичные компоненты**: узлы **{{ productName }}** ({{ apacheIgniteVariants }}), {{ apacheKafkaVariants }}, файловое хранилище — нарушение работоспособности может вывести систему из строя.
- **Важные компоненты**: {{ openSearchVariants }} — нарушение работоспособности не выводит систему из строя.
- **Вспомогательные компоненты**: мониторинг, дополнительные сервисы — не влияют на состояние системы.

## Сценарии и порядок восстановления {: #cluster_recovery_specific_scenarios }

### Полное восстановление кластера

- Требует полной остановки кластера, система временно утрачивает работоспособность
- Выполняется восстановление конфигурации и данных всех узлов из резервной копии
- Кластер снова запускается в полном составе
- Выполняется синхронизация данных между узлами — занимает некоторое время
- Последовательный запуск узлов с реконфигурацией кластера

При отказе всех узлов кластера восстанавливайте его в следующем порядке:

1. Остановите все службы на каждом узле кластера в следующем порядке: {{ nginxVariants }} → API Gateway → {{ productName }} → {{ apacheIgniteVariants }}.
2. Восстановите данные и конфигурацию **{{ productName }}** и служб на одном или нескольких узлах из резервной копии.
3. Настройте ссылки на общие файлы (Scripts).
4. Проверьте файлы конфигурации на всех узлах:

    - `/usr/share/comindware/configs/instance/<instanceName>.yml`
    - `/var/www/<instanceName>/adapterhost.yml`
    - `/var/www/<instanceName>/apigateway.yml`
    - `/var/www/<instanceName>/ignite.config`

5. Запустите все службы на каждом узле кластера в следующем порядке: {{ apacheIgniteVariants }} → {{ productName }} → API Gateway →  {{ nginxVariants }}.
6. Включите узлы в топологию кластера.
7. Проверьте синхронизацию данных между узлами: дождитесь сообщения об окончании ребалансировки: `INFO Skipping rebalancing (nothing scheduled)`.
8. Активируйте кластер.
9. Проверьте подключение каждого узла к сервисам {{ apacheKafkaVariants }}, {{ openSearchVariants }}.
10. Проверьте работоспособность кластера:

    - Убедитесь, что все узлы возвращают статус `200` на эндпоинте `api/health`.
    - Проверьте время отклика всех узлов.
    - Протестируйте балансировку нагрузки.

11. Выполните проверку целостности данных и работоспособности системы в целом.

### Восстановление одного узла кластера

- Не требует полной остановки кластера, узел временно выводится из состава кластера
- Выполняется восстановление конфигурации и данных узла из резервной по необходимости
- Выполняется возврат в состав кластера
- Выполняется синхронизация данных с другими узлами — занимает некоторое время

При отказе одного узла восстановление можно выполнить без остановки кластера:

1. Остановите все службы на узле в следующем порядке: {{ nginxVariants }} → API Gateway → {{ productName }} → {{ apacheIgniteVariants }}.
2. Очистите локальную базу данных узла.
3. Настройте ссылки на общие файлы (Scripts).
4. Проверьте файлы конфигурации на всех узлах:

    - `/usr/share/comindware/configs/instance/<instanceName>.yml`
    - `/var/www/<instanceName>/adapterhost.yml`
    - `/var/www/<instanceName>/apigateway.yml`
    - `/var/www/<instanceName>/ignite.config`

5. Запустите все службы на узле в следующем порядке: {{ apacheIgniteVariants }} → {{ productName }} → API Gateway →  {{ nginxVariants }}.
6. Выполните реконфигурацию кластера для подключения узла.
7. Проверьте синхронизацию данных с остальными узлами: дождитесь сообщения об окончании ребалансировки: `INFO Skipping rebalancing (nothing scheduled)`.
8. Проверьте подключение каждого узла к сервисам {{ apacheKafkaVariants }}, {{ openSearchVariants }}.
9. Проверьте работоспособность кластера:

    - Убедитесь, что все узлы возвращают статус `200` на эндпоинте `api/health`.
    - Проверьте время отклика всех узлов.
    - Протестируйте балансировку нагрузки.

10. Выполните проверку целостности данных и работоспособности системы в целом:

## Полезные приёмы

### Проверка топологии кластера

1. Проверьте подключение к {{ apacheIgniteVariants }}. Для этого выполните на восстановленном и соседнем узлах команду:

    ``` sh
    bash /usr/share/ignite/bin/control.sh --baseline
    ```

2. Удостоверьтесь, что топологии совпадают на всех узлах.

### Проверка ребалансировки кластера

3. Дождитесь сообщения: `INFO Skipping rebalancing (nothing scheduled)` в `igniteClient_*.log`.

### Блокировка запуска платформы до сборки кластера

4. В случае полного восстановления кластера создайте файл `hold.lock` в директории базы данных. Этот файл служит для блокировки передачи запросов из веб-интерфейса **{{ productName }}** в БД {{ apacheIgniteVariants }} до завершения ребалансировки узла.
5. Удалите файл `hold.lock`, чтобы снова активировать кластер.

### Проверка статуса узла {{ productName }}

1. Убедитесь, что эндпоинт `api/health` возвращает статус `200`. Проверяйте регулярно, например каждые 30 секунд.
2. Проверьте время отклика (не должно превышать 5&nbsp;секунд).
3. Проанализируйте журналы на предмет ошибок.
4. Проверьте синхронизацию данных между узлами.

### Проверка статуса {{ openSearchVariants }}

- Используйте эндпоинт `/_cluster/health` для проверки состояния
- Проверяйте состояние индексов и их репликации
- Отслеживайте производительность поисковых запросов

### Проверка статуса {{ apacheKafkaVariants }}

- Контролируйте состояние топиков и партиций.
- Отслеживайте задержки обработки сообщений.
- Контролируйте размер очередей сообщений.

## Устранение неполадок {: #cluster_recovery_troubleshooting .pageBreakBefore }

### Частые проблемы при восстановлении {: #cluster_recovery_common_issues }

- **Узел не подключается к кластеру {{ apacheIgniteVariants }}**: проверьте сетевое подключение между узлами, конфигурацию {{ apacheIgniteVariants }}, файрвол и сетевые настройки.
- **Ошибки синхронизации данных**: проверьте доступность NFS-сервера, права доступа к файлам, состояние дискового пространства, конфигурацию монтирования в `/etc/fstab`.
- **Проблемы с балансировщиком нагрузки**: проверьте конфигурацию балансировщика, доступность эндпоинта `api/health`, настройки проверки состояния узлов.
- **Проблемы с NFS-монтированием**: проверьте доступность NFS-сервера, настройки в `/etc/fstab`, права доступа к общим директориям.

### Журналы для диагностики {: #cluster_recovery_logs }

**Основные журналы {{ productName }}:**

- `heartbeat_*.log` — состояние экземпляра и процесс запуска
- `igniteClient_*.log` — подключение к {{ apacheIgniteVariants }} и ребалансировка кластера

**Журналы инфраструктуры:**

- Журналы {{ apacheIgniteVariants }} — состояние кластера хранилища данных.
- Журналы {{ openSearchVariants }} — состояние кластера журналирования транзакций.
- Журналы {{ apacheKafkaVariants }} — состояние очередей сообщений.

### Инструменты диагностики {: #cluster_recovery_diagnostic_tools }

**Проверка состояния узлов:**

``` sh
curl -X GET "http://<node-ip>/api/health"
```

**Проверка {{ apacheIgniteVariants }}:**

``` sh
bash /usr/share/ignite/bin/control.sh --baseline
```

**Проверка {{ openSearchVariants }}:**

``` sh
curl -X GET "localhost:9200/_cluster/health?pretty"
```

**Проверка {{ apacheKafkaVariants }}:**

``` sh
kafka-topics.sh --bootstrap-server localhost:9092 --list
```

### Практики, которых следует избегать {: #cluster_recovery_anti_patterns }

- **Не игнорируйте резервное копирование**: нерегулярное или неправильное резервное копирование данных может осложнить восстановление системы после сбоя.
- **Не пропускайте тестирование восстановления**: невыполнение регулярного тестирования процедур восстановления может привести к неготовности к авариям.
- **Не восстанавливайте несколько узлов одновременно**: одновременное восстановление нескольких узлов может привести к конфликтам данных.
- **Не игнорируйте реконфигурацию кластера**: после восстановления каждого узла необходимо синхронизировать данные в кластере.
- **Не нарушайте порядок остановки и запуска служб**: неправильный порядок может привести к повреждению данных или неработоспособности кластера.
- **Не игнорируйте проверки целостности**: всегда проверяйте целостность данных после восстановления.

<div class="relatedTopics" markdown="block">

--8<-- "related_topics_heading.md"

- [Установка, запуск, инициализация и остановка ПО][deploy_guide_linux]
- [Обновление кластера {{ productName }}][cluster_upgrade]
- [Системные требования {{ productName }}][system_requirements]
- [Резервное копирование. Настройка и запуск, просмотр журнала сеансов][backup_configure]

</div>

{% include-markdown ".snippets/hyperlinks_mkdocs_to_kb_map.md" %}

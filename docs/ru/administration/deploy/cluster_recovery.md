---
kbId: 5135
title: 'Кластер. Восстановление после аварий'
kbTitle: 'Кластер Comindware Platform. Восстановление после аварий'
tags:
    - Ignite
    - Grafana
    - Kafka
    - Loki
    - OpenSearch
    - Prometheus
    - администрирование
    - архитектура
    - балансировка нагрузки
    - восстановление
    - кластер
    - кластеризация
    - мониторинг
    - отказоустойчивость
    - развёртывание
    - резервное копирование
    - управление кластером
hide: tags
---

# Кластер {{ productName }}. Восстановление после аварий {: #cluster_recovery }

{% include-markdown ".snippets/experimental_feature.md" %}

## Введение {: #cluster_recovery_about }

**{{ productName }}** поддерживает кластерные конфигурации, которые обеспечивают высокую доступность, отказоустойчивость и горизонтальное масштабирование.

Здесь представлены рекомендации и процедуры восстановления ПО **{{ productName }}** в кластерных конфигурациях после сбоев.

## Средства, обеспечивающие надежность и восстановление кластеров {: #cluster_benefits }

Кластерная архитектура **{{ productName }}** позволяет восстанавливать систему благодаря следующим средствам:

- **проверка здоровья узлов**: все узлы предоставляют эндпоинт `api/health` для мониторинга состояния;
- **автоматическое перераспределение трафика**: балансировщик нагрузки должен автоматически исключать неисправные узлы;
- **резервные узлы**: кластеры {{ apacheIgniteVariants }}, {{ openSearchVariants }} и {{ apacheKafkaVariants }} обеспечивают избыточность во время восстановления;
- **распределённое хранилище**: DFS обеспечивает сохранность и целостность резервных копий и файлов для всех узлов.

## Стратегические принципы обеспечения надёжности системы {: #cluster_recovery_strategic_principles .pageBreakBefore }

### Подготовка к авариям {: #cluster_recovery_preparation_philosophy }

Чтобы оперативно восстанавливать систему в аварийных ситуациях, рекомендуется реализовать следующие меры:

- обеспечить надёжное резервирование всех компонентов и резервное копирование всех данных, см. [стратегию резервного копирования](#cluster_recovery_backup_strategy);
- регулярно выполнять [тестирование восстановления](#cluster_recovery_testing) — любые проблемы с восстановлением следует выявлять и устранять в процессе тестирования;
- подготовить план действий в нештатных ситуациях;
- обучить специалистов процедурам аварийного восстановления, чтобы команда тратила время на их изучение.

### Стратегия резервного копирования {: #cluster_recovery_backup_strategy }

#### Многоуровневый подход к резервному копированию

Современные системы требуют многоуровневого подхода к резервному копированию, где каждый уровень решает свои задачи.

Различные периоды хранения данных (от 1 часа до 1 месяца) для каждого уровня позволяют сбалансировать требования к надёжности и стоимости хранения резервных копий:

- **Полные резервные копии всей системы** (еженедельно для продуктивных систем, ежемесячно для тестовых) — обеспечивают точку восстановления для критических ситуаций.
- **Инкрементальные копии** (ежедневно для всех систем) — минимизируют потерю данных при некритических сбоях.
- **Копии базы данных {{ productName }}** (каждые 4–12 часов в зависимости от критичности) — обеспечивают быстрое восстановление конфигурации и данных экземпляра ПО в непредвиденных обстоятельствах.

Кроме того, следует применять различные подходы к резервному копированию в зависимости от контура, в котором эксплуатируется экземпляр системы.

#### Подходы к резервному копированию по контурам

Ниже представлен **пример** параметров резервного копирования, которые **следует адаптировать** к особенностям вашей конкретной системы и бизнес-требованиям.

- **Продуктивный контур**
    - **Полные копии**: еженедельно (воскресенье), хранить 1 месяц.
    - **Инкрементальные копии**: ежедневно (00:00–03:00), хранить последние 15 копий.
    - **Копии базы данных**: не реже 1 раза в 4 часа, хранить не менее одного дня.
    - **Автоматизация**: VEEAM для полных и инкрементальных копий, платформа **{{ productName }}** для платформенных копий.
- **Предпродуктивный контур**
    - **Полные копии**: ежемесячно, хранить 1 месяц.
    - **Инкрементальные копии**: ежедневно (00:00–03:00), хранить последние 15 копий.
    - **Копии базы данных**: каждые 12 часов, хранить последние 6 копий.
- **Тестовый контур**
    - **Полные копии**: ежемесячно, хранение 1 месяц.
    - **Инкрементальные копии**: ежедневно (00:00–03:00), хранить последние 15 копий.
    - **Копии базы данных**: каждые 8 часов, хранить последние 4 копии.

### Тестирование процедур восстановления {: #cluster_recovery_testing }

Для обеспечения готовности к возможным авариям необходимо регулярно тестировать возможность восстановления системы.

Регулярное тестирование помогает:

- выявить проблемы в процедурах восстановления до того, как ими придётся воспользоваться;
- обучить команду порядку действий в нештатных ситуациях;
- проверить актуальность резервных копий;
- оценить время восстановления (RTO) и потенциальные потери данных (RPO).

Следует тестировать следующие сценарии восстановления:

- **[восстановление одного узла](#cluster_recovery_scenarios_single_node)** — наиболее вероятный сценарий, требуется тестировать регулярно;
- **[полное восстановление кластера](#cluster_recovery_scenarios_complete)** — критический сценарий, следует тестировать реже, но тщательно;
- **восстановление в нетипичных условиях** — тестирует устойчивость установленных процедур к непредвиденным обстоятельствам, необязательно, но рекомендуется.

См. _[Рекомендации по восстановлению кластера](#cluster_recovery_strategies)_.

### Мониторинг состояния системы {: #cluster_recovery_monitoring_culture }

В любой конфигурации необходимо обеспечить непрерывный мониторинг работоспособности **{{ productName }}** в целом и каждого компонента в отдельности.

Эффективный мониторинг помогает:

- предотвратить сбои до их возникновения;
- оперативно диагностировать проблемы;
- оценивать эффективность восстановительных процедур.

Следует предусмотреть следующие средства мониторинга:

- автоматические уведомления о критических событиях;
- регулярные проверки состояния компонентов;
- журнал инцидентов;
- Мониторинг резервного копирования.

## Рекомендации по восстановлению кластера {: #cluster_recovery_strategies .pageBreakBefore }

!!! warning "Фактические пути и имена файлов"

    При выполнении инструкций будьте внимательны: указывайте фактические имена файлов и пути, которые используются в вашей системе.

    Такие имена указаны в угловых скобках, например:

    - `<instanceName>` — имя экземпляра ПО;
    - `<node-ip>` — IP-адрес узла.
    
    См. _«[Пути и содержимое директорий экземпляра ПО][paths]»_.

### Общий порядок восстановления {: #cluster_recovery_sequence }

При восстановлении кластера **{{ productName }}** соблюдайте рекомендованный порядок:

1. **Диагностика проблемы** — определите причину сбоя и масштаб повреждений:

    - Проверьте состояние узла с помощью эндпоинта `api/health`, на работающих узлах он должен возвращать статус `200`.
    - Проверьте журналы состояния экземпляра **{{ productName }}** (`heartbeat_*.log`).
    - Проверьте журналы {{ apacheIgniteVariants }} (`igniteClient_*.log`).
    - Проверьте состояние файловой системы.
    - Проверьте доступность сетевых ресурсов.
    - Проверьте состояние и топологию кластера {{ apacheIgniteVariants }} со всех узлов.

2. **Запланируйте восстановление**:

    - Выберите подходящую стратегию восстановления: **восстановление одного узла** или **полное восстановление** кластера.
    - Подготовьте план действий и необходимые ресурсы.

3. **Выполните восстановление**: следуйте процедурам для выбранной стратегии. См. _[Сценарии и порядок восстановления](#cluster_recovery_scenarios)_.
4. **Контролируйте работоспособность кластера в процессе и после восстановления**:

    - Отслеживайте состояние всех компонентов и сервисов.
    - Контролируйте состояние и топологию кластера {{ apacheIgniteVariants }}.
    - Анализируйте файловые журналы на предмет наличия ошибок и предупреждений, которые могут помешать восстановлению.
    - Замеряйте производительность системы.
    - Будьте готовы к немедленному откату при необходимости.

### Мониторинг во время восстановления {: #cluster_recovery_monitoring }

В процессе восстановления кластера необходимо контролировать состояние кластера в целом и отдельных компонентов:

- постоянно контролируйте эндпоинт `api/health`, на работающих узлах он должен возвращать статус `200`;
- анализируйте журналы состояния **{{ productName }}** (`heartbeat_*.log`);
- контролируйте журнал {{ apacheIgniteVariants }} (`igniteClient_*.log`);
- контролируйте состояние топологии кластера {{ apacheIgniteVariants }} со всех узлов во время восстановления;
- контролируйте распределение нагрузки между узлами;
- контролируйте синхронизацию данных между узлами.

### Проверка после восстановления {: #cluster_recovery_verification }

- Дождитесь сообщения об окончании ребалансировки кластера в журнале  {{ apacheIgniteVariants }} (`igniteClient_*.log`):

    ```
    INFO Skipping rebalancing (nothing scheduled)
    ```

- Проверьте результирующую топологию {{ apacheIgniteVariants }} с нескольких узлов.

## Критичность компонентов {: #cluster_recovery_component_criticality }

При планировании, конфигурировании и восстановлении системы следует учитывать значение каждого компонента для работоспособности системы:

- **критичные компоненты**: узлы **{{ productName }}**, {{ apacheIgniteVariants }}, {{ apacheKafkaVariants }}, файловое хранилище — нарушение работоспособности может вывести систему из строя;
- **важные компоненты**: {{ openSearchVariants }} — нарушение работоспособности не выводит систему из строя;
- **вспомогательные компоненты**: мониторинг, дополнительные сервисы — не влияют на состояние системы.

## Сценарии и порядок восстановления {: #cluster_recovery_scenarios }

### Полное восстановление кластера {: #cluster_recovery_scenarios_complete }

Полное восстановление накладывает следующие ограничения:

- требуется полная остановка кластера, система временно утрачивает работоспособность;
- выполняется восстановление конфигурации и данных всех узлов из резервной копии;
- кластер снова запускается в полном составе;
- выполняется синхронизация данных между узлами, что занимает некоторое время;
- производится последовательный запуск узлов с реконфигурацией кластера.

При отказе всех узлов кластера восстанавливайте его в указанном ниже порядке:

1. Остановите все службы на каждом узле кластера в следующем порядке: {{ nginxVariants }} → API Gateway → {{ productName }} → {{ apacheIgniteVariants }}.
2. Восстановите из резервной копии данные и конфигурацию **{{ productName }}** и служб на одном или нескольких узлах.
3. Настройте ссылки на общие файлы (например, директорию `Scripts`), расположенные в файловом хранилище.
4. Проверьте файлы конфигурации на всех узлах:

    - `/usr/share/comindware/configs/instance/<instanceName>.yml`
    - `/var/www/<instanceName>/adapterhost.yml`
    - `/var/www/<instanceName>/apigateway.yml`
    - `/var/www/<instanceName>/ignite.config`

5. Запустите все службы на каждом узле кластера в следующем порядке: {{ apacheIgniteVariants }} → {{ productName }} → API Gateway →  {{ nginxVariants }}.
6. Включите узлы в топологию кластера.
7. Проверьте синхронизацию данных между узлами: дождитесь сообщения об окончании ребалансировки в файле `igniteClient_*.log` {{ apacheIgniteVariants }}:

    ```
    INFO Skipping rebalancing (nothing scheduled)
    ```

8. Активируйте кластер.
9. Проверьте подключение каждого узла к сервисам {{ apacheKafkaVariants }} и {{ openSearchVariants }}.
10. Проверьте работоспособность кластера:

    - убедитесь, что все узлы возвращают статус `200` на эндпоинте `api/health`;
    - проверьте время отклика всех узлов;
    - протестируйте балансировку нагрузки.

11. Выполните проверку целостности данных и работоспособности системы в целом.

### Восстановление одного узла кластера {: #cluster_recovery_scenarios_single_node }

Восстановление одного узла накладывает следующие ограничения:

- не требуется полная остановка кластера, узел временно выводится из состава кластера;
- выполняется восстановление конфигурации и данных узла из резервной по необходимости;
- выполняется возврат узла в состав кластера;
- выполняется синхронизация данных с другими узлами, что занимает некоторое время.

При отказе одного узла восстановление можно выполнить без остановки кластера в указанном ниже порядке:

1. Остановите все службы на узле в следующем порядке: API Gateway → {{ productName }} → {{ apacheIgniteVariants }}.
2. Очистите локальную базу данных узла.
3. Настройте ссылки на общие файлы (например, директорию `Scripts`), расположенные в файловом хранилище.
4. Проверьте файлы конфигурации на всех узлах:

    - `/usr/share/comindware/configs/instance/<instanceName>.yml`
    - `/var/www/<instanceName>/adapterhost.yml`
    - `/var/www/<instanceName>/apigateway.yml`
    - `/var/www/<instanceName>/ignite.config`

5. Запустите все службы на узле в следующем порядке: {{ apacheIgniteVariants }} → {{ productName }} → API Gateway.
6. Выполните реконфигурацию кластера для подключения узла.
7. Проверьте синхронизацию данных с остальными узлами: дождитесь сообщения об окончании ребалансировки в файле `igniteClient_*.log` {{ apacheIgniteVariants }}:

    ```
    INFO Skipping rebalancing (nothing scheduled)
    ```

8. Проверьте подключение каждого узла к сервисам {{ apacheKafkaVariants }}, {{ openSearchVariants }}.
9. Проверьте работоспособность кластера:

    - убедитесь, что все узлы возвращают статус `200` на эндпоинте `api/health`;
    - проверьте время отклика всех узлов;
    - протестируйте балансировку нагрузки.

10. Выполните проверку целостности данных и работоспособности системы в целом.

## Полезные приёмы {: #cluster_recovery_tips .pageBreakBefore }

### Проверка топологии кластера {: #cluster_recovery_tips_cluster_topology_check }

1. Проверьте подключение к {{ apacheIgniteVariants }}. Для этого выполните на восстановленном и соседнем узлах команду:

    ``` sh
    bash /usr/share/ignite/bin/control.sh --baseline
    ```

2. Удостоверьтесь, что топологии совпадают на всех узлах.

### Проверка ребалансировки кластера {: #cluster_recovery_tips_cluster_rebalancing_check }

Удостоверьтесь, что в файле `igniteClient_*.log` {{ apacheIgniteVariants }} имеется сообщение об окончании ребалансировки:

    ```
    INFO Skipping rebalancing (nothing scheduled)
    ```

### Блокировка запуска {{ productName }} до сборки кластера {: #cluster_recovery_tips_lock }

В случае полного восстановления кластера следует заблокировать возможность запуска **{{ productName }}** до тех пор, пока кластер не будет собран после восстановления.

1. Создайте файл `hold.lock` в директории базы данных. Этот файл служит для блокировки передачи запросов из веб-интерфейса **{{ productName }}** в БД {{ apacheIgniteVariants }} до завершения ребалансировки узлов.
2. Удалите файл `hold.lock`, чтобы снова активировать кластер.

### Проверка статуса узла {{ productName }} {: #cluster_recovery_tips_note_status }

1. Убедитесь, что эндпоинт `api/health` возвращает статус `200`. Проверяйте регулярно, например каждые 30 секунд.
2. Проверьте время отклика (не должно превышать 5&nbsp;секунд).
3. Проанализируйте журналы на предмет ошибок.
4. Проверьте синхронизацию данных между узлами.

### Проверка статуса {{ openSearchVariants }} {: #cluster_recovery_tips_opensearch_status }

- Используйте эндпоинт `/_cluster/health` для проверки состояния.
- Проверяйте состояние индексов и их репликации.
- Отслеживайте производительность поисковых запросов.

### Проверка статуса {{ apacheKafkaVariants }} {: #cluster_recovery_tips_kafka_status }

- Контролируйте состояние топиков и партиций.
- Отслеживайте задержки обработки сообщений.
- Контролируйте размер очередей сообщений.

## Устранение неполадок {: #cluster_recovery_troubleshooting .pageBreakBefore }

### Типовые проблемы при восстановлении {: #cluster_recovery_common_issues }

- **Узел не подключается к кластеру {{ apacheIgniteVariants }}**: проверьте сетевое соединение между узлами, конфигурацию {{ apacheIgniteVariants }}, сетевой экран и сетевые настройки.
- **Ошибки синхронизации данных**: проверьте доступность NFS-сервера, права доступа к файлам, состояние дискового пространства, конфигурацию монтирования в `/etc/fstab`.
- **Проблемы с балансировщиком нагрузки**: проверьте конфигурацию балансировщика, доступность эндпоинта `api/health`, настройки проверки состояния узлов.
- **Проблемы с NFS-монтированием**: проверьте доступность NFS-сервера, настройки в `/etc/fstab`, права доступа к общим директориям.

### Журналы для диагностики {: #cluster_recovery_logs }

В процессе диагностики состояния системы используйте следующие журналы:

- **Основные журналы {{ productName }}:**
    - `heartbeat_*.log` — состояние экземпляра и процесс запуска
    - `igniteClient_*.log` — подключение к {{ apacheIgniteVariants }} и ребалансировка кластера
- **Журналы инфраструктуры:**
    - Журналы {{ apacheIgniteVariants }} — состояние кластера хранилища данных.
    - Журналы {{ openSearchVariants }} — состояние кластера журналирования транзакций.
    - Журналы {{ apacheKafkaVariants }} — состояние очередей сообщений.

### Инструменты диагностики {: #cluster_recovery_diagnostic_tools }

В процессе диагностики состояния системы используйте следующие инструменты:

- **Проверка состояния узлов:**

    ``` sh
    curl -X GET "http://<node-ip>/api/health"
    ```

- **Проверка {{ apacheIgniteVariants }}:**

    ``` sh
    bash /usr/share/ignite/bin/control.sh --baseline
    ```

- **Проверка {{ openSearchVariants }}:**

    ``` sh
    curl -X GET "localhost:9200/_cluster/health?pretty"
    ```

- **Проверка {{ apacheKafkaVariants }}:**

    ``` sh
    kafka-topics.sh --bootstrap-server localhost:9092 --list
    ```

### Практики, которых следует избегать {: #cluster_recovery_anti_patterns }

- **Не игнорируйте резервное копирование**: нерегулярное или неправильное резервное копирование данных может осложнить восстановление системы после сбоя.
- **Не пропускайте тестирование восстановления**: невыполнение регулярного тестирования процедур восстановления может привести к неготовности к авариям.
- **Не восстанавливайте несколько узлов одновременно**: одновременное восстановление нескольких узлов может привести к конфликтам данных.
- **Не игнорируйте реконфигурацию кластера**: после восстановления каждого узла необходимо синхронизировать данные в кластере.
- **Не нарушайте порядок остановки и запуска служб**: неправильный порядок может привести к повреждению данных или неработоспособности кластера.
- **Не игнорируйте проверки целостности**: всегда проверяйте целостность данных после восстановления.

<div class="relatedTopics" markdown="block">

--8<-- "related_topics_heading.md"

- [Установка, запуск, инициализация и остановка ПО][deploy_guide_linux]
- [Обновление кластера {{ productName }}][cluster_upgrade]
- [Системные требования {{ productName }}][system_requirements]
- [Резервное копирование. Настройка и запуск, просмотр журнала сеансов][backup_configure]
- [Пути и содержимое директорий экземпляра ПО][paths]
- [Обеспечение высокой доступности и отказоустойчивости {{ productName }}][availability_fault_tolerance]

</div>

{% include-markdown ".snippets/hyperlinks_mkdocs_to_kb_map.md" %}
